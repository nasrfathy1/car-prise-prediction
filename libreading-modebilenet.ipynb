{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# using the 39 phone set proposed in (Lee & Hon, 1989)\n# Table 3. Mapping from 61 classes to 39 classes, as proposed by Lee and Hon, (Lee & Hon,\n# 1989). The phones in the left column are folded into the labels of the right column. The\n# remaining phones are left intact.}\n!pip install trax\npip install --upgrade jax jaxlib\npip install --upgrade trax\nimport trax\nimport trax.layers as tl\nimport random as rnd\nimport tensorflow as tf\nimport json\nimport numpy as np\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.models import Model\n\nimport itertools\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.preprocessing.image import img_to_array\n\n\n\nfrom trax.fastmath import numpy as fastnp\nimport numpy as np\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-05T18:23:21.617885Z","iopub.execute_input":"2023-06-05T18:23:21.619122Z","iopub.status.idle":"2023-06-05T18:23:21.626425Z","shell.execute_reply.started":"2023-06-05T18:23:21.619084Z","shell.execute_reply":"2023-06-05T18:23:21.625271Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"\ndef collect_video_files(data_type, resp, root_dir):\n    if resp == 'lipspeakers':\n        speakerDir = root_dir+'/lipspeakers'\n    elif resp == 'volunteers':\n        speakerDir = root_dir+'/volunteers'\n    else:\n        speakerDir = root_dir\n\n    fileName = f'{data_type}_dict.json'\n    data = open(speakerDir+os.sep+fileName).read()\n    data_dict = json.loads(data)\n\n    with open(f'{speakerDir}/data_phn.txt', 'r') as f:\n        lines = f.readlines()\n    video_list = [l.strip() for l in lines]\n\n    return data_dict, video_list, speakerDir\n\n\n\n\nvideo_path = os.path.join('/kaggle/input/volunt')\nspkr_type = 'volunteerss'\n\nlip_data_dict, lip_video_list, lip_data_dir = collect_video_files('data', 'volunteers',video_path)\n\n\nrnd.shuffle(lip_video_list)\nlip_video_list=list(set(lip_video_list))\ntrain_size=int(len(lip_video_list)*.9)\ntrain_list=lip_video_list[:train_size]\n\nval_list=lip_video_list[train_size:]","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:05:51.053516Z","iopub.execute_input":"2023-06-05T18:05:51.054362Z","iopub.status.idle":"2023-06-05T18:05:51.237683Z","shell.execute_reply.started":"2023-06-05T18:05:51.054320Z","shell.execute_reply":"2023-06-05T18:05:51.236334Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"len(train_list),len(val_list)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:05:51.239035Z","iopub.execute_input":"2023-06-05T18:05:51.239360Z","iopub.status.idle":"2023-06-05T18:05:51.249930Z","shell.execute_reply.started":"2023-06-05T18:05:51.239328Z","shell.execute_reply":"2023-06-05T18:05:51.249021Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(4672, 520)"},"metadata":{}}]},{"cell_type":"code","source":"phoneme_set_39_list = [\n    'iy', 'ih', 'eh', 'ae', 'ah', 'uw', 'uh', 'aa', 'ey', 'ay', 'oy', 'aw', 'ow',\n    'l', 'r', 'y', 'w', 'er', 'm', 'n', 'ng', 'ch', 'jh', 'dh', 'b', 'd', 'dx',\n    'g', 'p', 't', 'k', 'z', 'v', 'f', 'th', 's', 'sh', 'hh', 'sil'\n]\ndef get_vocabs(phoneme_set_39_list):\n    phonem_nunmber={'<pad>':0}\n    number_phonem={0:'<pad>'}\n    for phonem in phoneme_set_39_list:\n        phonem_nunmber[phonem]=len(phonem_nunmber)\n        number_phonem[len(number_phonem)]=phonem\n    return phonem_nunmber,number_phonem\n\nphonem_nunmber,number_phonem=get_vocabs(phoneme_set_39_list)\nlen(phonem_nunmber),len(number_phonem)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:05:51.251824Z","iopub.execute_input":"2023-06-05T18:05:51.252097Z","iopub.status.idle":"2023-06-05T18:05:51.263013Z","shell.execute_reply.started":"2023-06-05T18:05:51.252065Z","shell.execute_reply":"2023-06-05T18:05:51.262273Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(40, 40)"},"metadata":{}}]},{"cell_type":"code","source":"mobile = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, \n                                                weights='imagenet',input_shape=(224,224,3))\noutput=mobile.output\noutput=Flatten(name='flatten')(output)\noutput=Dense(1024,activation='relu')(output)\nmodel = Model(inputs=mobile.input, outputs=output)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:05:51.264117Z","iopub.execute_input":"2023-06-05T18:05:51.264453Z","iopub.status.idle":"2023-06-05T18:05:56.559900Z","shell.execute_reply.started":"2023-06-05T18:05:51.264411Z","shell.execute_reply":"2023-06-05T18:05:56.558637Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9406464/9406464 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"def generte_date(data,data_labels,data_dir,phonem_nunmber,model):\n    data_size=len(data)\n    idx=0\n    while True:\n        if idx>=data_size:\n            idx=0\n\n\n        video=data[idx]\n        spk,vdo = video.split('_')[:2]\n        image_name = vdo.split('.')[0]+'_'\n\n        list_IDs_temp = sorted([image_file for image_file in list(data_labels) if image_name in image_file])\n        list_IDs_temp=sorted([image_file for image_file in list_IDs_temp if image_file in os.listdir(data_dir+'/'+spk)])\n\n        idx+=1\n        X = np.zeros((len(list_IDs_temp),224,224,3))\n        Y = []\n        for i, ID in enumerate(list_IDs_temp):\n\n            image = load_img(data_dir+'/'+spk+'/'+ID,target_size=(224,224))\n            image=img_to_array(image)\n            image=preprocess_input(image)\n            X[i] = image\n\n            Y.append(phonem_nunmber[data_labels[ID]])\n        X=model.predict(X,verbose=0)\n        Y=np.array(Y)\n        yield ((X,Y))","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:26:02.984446Z","iopub.execute_input":"2023-06-05T18:26:02.985374Z","iopub.status.idle":"2023-06-05T18:26:02.997456Z","shell.execute_reply.started":"2023-06-05T18:26:02.985337Z","shell.execute_reply":"2023-06-05T18:26:02.996512Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"X,Y=next(generte_date(train_list,lip_data_dict,lip_data_dir,phonem_nunmber,model))\nX.shape,Y.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:26:03.522044Z","iopub.execute_input":"2023-06-05T18:26:03.523038Z","iopub.status.idle":"2023-06-05T18:26:04.315349Z","shell.execute_reply.started":"2023-06-05T18:26:03.523005Z","shell.execute_reply":"2023-06-05T18:26:04.314295Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"((34, 1024), (34,))"},"metadata":{}}]},{"cell_type":"code","source":"boundaries =  [8,   16,  32, 64, 128, 256]\nbatch_sizes = [128, 64, 32, 16,    8,   4,2]\n# Create the generators.\ntrain_batch_stream = trax.data.BucketByLength(\n    boundaries, batch_sizes,\n    length_keys=[0, 1]  # As before: count inputs and targets to length.\n)(generte_date(train_list,lip_data_dict,lip_data_dir,phonem_nunmber,model))\n\nval_batch_stream = trax.data.BucketByLength(\n    boundaries, batch_sizes,\n    length_keys=[0, 1]  # As before: count inputs and targets to length.\n)(generte_date(val_list,lip_data_dict,lip_data_dir,phonem_nunmber,model))\n\n\ntrain_batch_stream = trax.data.AddLossWeights(id_to_mask=0)(train_batch_stream)\nval_batch_stream = trax.data.AddLossWeights(id_to_mask=0)(val_batch_stream)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:26:15.916619Z","iopub.execute_input":"2023-06-05T18:26:15.918018Z","iopub.status.idle":"2023-06-05T18:26:15.926511Z","shell.execute_reply.started":"2023-06-05T18:26:15.917978Z","shell.execute_reply":"2023-06-05T18:26:15.925397Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"%%time\nX,Y,M=next(train_batch_stream)\nX.shape,Y.shape,M.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:26:54.709047Z","iopub.execute_input":"2023-06-05T18:26:54.710076Z","iopub.status.idle":"2023-06-05T18:27:25.138142Z","shell.execute_reply.started":"2023-06-05T18:26:54.710037Z","shell.execute_reply":"2023-06-05T18:27:25.137101Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"CPU times: user 2min 11s, sys: 3min 28s, total: 5min 39s\nWall time: 30.4 s\n","output_type":"stream"},{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"((16, 64, 1024), (16, 64), (16, 64))"},"metadata":{}}]},{"cell_type":"code","source":"# UNQ_C1\n# GRADED FUNCTION\ndef input_encoder_fn(n_encoder_layers):\n    \"\"\" Input encoder runs on the input sentence and creates\n    activations that will be the keys and values for attention.\n    \n    Args:\n        input_vocab_size: int: vocab size of the input\n        d_model: int:  depth of embedding (n_units in the LSTM cell)\n        n_encoder_layers: int: number of LSTM layers in the encoder\n    Returns:\n        tl.Serial: The input encoder\n    \"\"\"\n    \n    # create a serial network\n    input_encoder = tl.Serial( \n\n        # feed the embeddings to the LSTM layers. It is a stack of n_encoder_layers LSTM layers\n        [tl.LSTM(n_units=1024) for _ in range(n_encoder_layers)]\n        ### END CODE HERE ###\n    )\n\n    return input_encoder","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:33:13.193451Z","iopub.execute_input":"2023-06-05T18:33:13.194417Z","iopub.status.idle":"2023-06-05T18:33:13.200567Z","shell.execute_reply.started":"2023-06-05T18:33:13.194385Z","shell.execute_reply":"2023-06-05T18:33:13.199409Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# UNQ_C2\n# GRADED FUNCTION\ndef pre_attention_decoder_fn(mode, target_vocab_size, d_model):\n    \"\"\" Pre-attention decoder runs on the targets and creates\n    activations that are used as queries in attention.\n    \n    Args:\n        mode: str: 'train' or 'eval'\n        target_vocab_size: int: vocab size of the target\n        d_model: int:  depth of embedding (n_units in the LSTM cell)\n    Returns:\n        tl.Serial: The pre-attention decoder\n    \"\"\"\n    \n    # create a serial network\n    pre_attention_decoder = tl.Serial(\n        \n        ### START CODE HERE ###\n        # shift right to insert start-of-sentence token and implement\n        # teacher forcing during training\n        tl.ShiftRight(),\n\n        # run an embedding layer to convert tokens to vectors\n        tl.Embedding(target_vocab_size,d_model),\n\n        # feed to an LSTM layer\n        tl.LSTM(d_model)\n        ### END CODE HERE ###\n    )\n    \n    return pre_attention_decoder","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:33:14.234148Z","iopub.execute_input":"2023-06-05T18:33:14.234462Z","iopub.status.idle":"2023-06-05T18:33:14.241436Z","shell.execute_reply.started":"2023-06-05T18:33:14.234436Z","shell.execute_reply":"2023-06-05T18:33:14.240397Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# UNQ_C3\n# GRADED FUNCTION\ndef prepare_attention_input(encoder_activations, decoder_activations, inputs):\n    \"\"\"Prepare queries, keys, values and mask for attention.\n    \n    Args:\n        encoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the input encoder\n        decoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the pre-attention decoder\n        inputs fastnp.array(batch_size, padded_input_length): input tokens\n    \n    Returns:\n        queries, keys, values and mask for attention.\n    \"\"\"\n    \n    ### START CODE HERE ###\n    print(f'encoder_activations is {encoder_activations.shape}')\n    # set the keys and values to the encoder activations\n    keys = encoder_activations\n    values = encoder_activations\n\n    \n    # set the queries to the decoder activations\n    queries = decoder_activations\n    \n    # generate the mask to distinguish real tokens from padding\n    # hint: inputs is positive for real tokens and 0 where they are padding\n    mask =np.sum(inputs,axis=2)\n    mask=mask!=0\n    ### END CODE HERE ###\n    \n    # add axes to the mask for attention heads and decoder length.\n    mask = fastnp.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\n    \n    # broadcast so mask shape is [batch size, attention heads, decoder-len, encoder-len].\n    # note: for this assignment, attention heads is set to 1.\n    mask = mask + fastnp.zeros((1, 1, decoder_activations.shape[1], 1))\n    \n        \n    \n    return queries, keys, values, mask","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:33:14.914117Z","iopub.execute_input":"2023-06-05T18:33:14.915106Z","iopub.status.idle":"2023-06-05T18:33:14.923453Z","shell.execute_reply.started":"2023-06-05T18:33:14.915072Z","shell.execute_reply":"2023-06-05T18:33:14.922369Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# UNQ_C4\n# GRADED FUNCTION\ndef NMTAttn(input_vocab_size=33300,\n            target_vocab_size=len(phonem_nunmber),\n            d_model=1024,\n            n_encoder_layers=2,\n            n_decoder_layers=2,\n            n_attention_heads=1,\n            attention_dropout=0.1,\n            mode='train'):\n    \"\"\"Returns an LSTM sequence-to-sequence model with attention.\n\n    The input to the model is a pair (input tokens, target tokens), e.g.,\n    an English sentence (tokenized) and its translation into German (tokenized).\n\n    Args:\n    input_vocab_size: int: vocab size of the input\n    target_vocab_size: int: vocab size of the target\n    d_model: int:  depth of embedding (n_units in the LSTM cell)\n    n_encoder_layers: int: number of LSTM layers in the encoder\n    n_decoder_layers: int: number of LSTM layers in the decoder after attention\n    n_attention_heads: int: number of attention heads\n    attention_dropout: float, dropout for the attention layer\n    mode: str: 'train', 'eval' or 'predict', predict mode is for fast inference\n\n    Returns:\n    An LSTM sequence-to-sequence model with attention.\n    \"\"\"\n\n    ### START CODE HERE ###\n    \n    # Step 0: call the helper function to create layers for the input encoder\n    input_encoder = input_encoder_fn(n_encoder_layers)\n\n    # Step 0: call the helper function to create layers for the pre-attention decoder\n    pre_attention_decoder = pre_attention_decoder_fn(mode, target_vocab_size, d_model)\n\n    # Step 1: create a serial network\n    model = tl.Serial( \n        \n      # Step 2: copy input tokens and target tokens as they will be needed later.\n      tl.Select([0,1,0,1]),\n        \n      # Step 3: run input encoder on the input and pre-attention decoder the target.\n      tl.Parallel(input_encoder,pre_attention_decoder),\n        \n      # Step 4: prepare queries, keys, values and mask for attention.\n      tl.Fn('PrepareAttentionInput', prepare_attention_input, n_out=4),\n        \n      # Step 5: run the AttentionQKV layer\n      # nest it inside a Residual layer to add to the pre-attention decoder activations(i.e. queries)\n      tl.Residual(tl.AttentionQKV(d_model, n_heads=n_attention_heads, dropout=attention_dropout, mode=mode)),\n      \n      # Step 6: drop attention mask (i.e. index = None\n      tl.Select([0,2]),\n        \n      # Step 7: run the rest of_de the RNN decoder\n      [tl.LSTM(d_model) for _ in range(n_decoder_layers)],\n        \n      # Step 8: prepare output by making it the right size\n      tl.Dense(target_vocab_size),   \n      # Step 9: Log-softmax for output\n      tl.LogSoftmax()\n    )\n    \n    ### END CODE HERE\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:33:18.465277Z","iopub.execute_input":"2023-06-05T18:33:18.466425Z","iopub.status.idle":"2023-06-05T18:33:18.477251Z","shell.execute_reply.started":"2023-06-05T18:33:18.466383Z","shell.execute_reply":"2023-06-05T18:33:18.476162Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# UNQ_C5\n# GRADED PART\nfrom trax.supervised import training\ndef train_task_function(train_batch_stream):\n    \"\"\"Returns a trax.training.TrainTask object.\n\n    Args:\n    train_batch_stream generator: labeled data generator\n\n    Returns:\n    A trax.training.TrainTask object.\n    \"\"\"\n    return training.TrainTask(\n\n        ### START CODE HERE\n\n        # use the train batch stream as labeled (\n        labeled_data= train_batch_stream,\n\n        # use the cross entropy loss\n        loss_layer= tl.CrossEntropyLoss(),\n\n        # use the Adam optimizer with learning rate of 0.01\n        optimizer= trax.optimizers.Adam(0.001),\n\n        # use the `trax.lr.warmup_and_rsqrt_decay` as th.01e learning rate schedule\n        # have 1000 warmup steps with a max value of 0.01\n        \n\n        # have a checkpoint every 10 steps\n        n_steps_per_checkpoint= 10\n\n        ### END CODE HERE\n    )","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:33:20.173915Z","iopub.execute_input":"2023-06-05T18:33:20.174799Z","iopub.status.idle":"2023-06-05T18:33:20.181085Z","shell.execute_reply.started":"2023-06-05T18:33:20.174768Z","shell.execute_reply":"2023-06-05T18:33:20.180125Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"train_task = train_task_function(train_batch_stream)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:33:20.912166Z","iopub.execute_input":"2023-06-05T18:33:20.913040Z","iopub.status.idle":"2023-06-05T18:33:27.246590Z","shell.execute_reply.started":"2023-06-05T18:33:20.913008Z","shell.execute_reply":"2023-06-05T18:33:27.244961Z"},"trusted":true},"execution_count":92,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_task \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_task_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batch_stream\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[91], line 24\u001b[0m, in \u001b[0;36mtrain_task_function\u001b[0;34m(train_batch_stream)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_task_function\u001b[39m(train_batch_stream):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a trax.training.TrainTask object.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    A trax.training.TrainTask object.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m training\u001b[38;5;241m.\u001b[39mTrainTask(\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m### START CODE HERE\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# use the train batch stream as labeled (\u001b[39;00m\n\u001b[1;32m     18\u001b[0m         labeled_data\u001b[38;5;241m=\u001b[39m train_batch_stream,\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# use the cross entropy loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         loss_layer\u001b[38;5;241m=\u001b[39m tl\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(),\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m         \u001b[38;5;66;03m# use the Adam optimizer with learning rate of 0.01\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m \u001b[43mtrax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m         \u001b[38;5;66;03m# use the `trax.lr.warmup_and_rsqrt_decay` as th.01e learning rate schedule\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# have 1000 warmup steps with a max value of 0.01\u001b[39;00m\n\u001b[1;32m     28\u001b[0m         \n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# have a checkpoint every 10 steps\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         n_steps_per_checkpoint\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m         \u001b[38;5;66;03m### END CODE HERE\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     )\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in scope \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scope_str) \u001b[38;5;28;01mif\u001b[39;00m scope_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[38;5;241m=\u001b[39m err_str\u001b[38;5;241m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_exception_message_and_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_str\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[38;5;241m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(exception)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mwith_traceback(exception\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/gin/config.py:516\u001b[0m, in \u001b[0;36m_make_meta_call_wrapper.<locals>.meta_call_wrapper\u001b[0;34m(new_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__bases__\u001b[39m \u001b[38;5;241m==\u001b[39m (\u001b[38;5;28mcls\u001b[39m,):\n\u001b[1;32m    515\u001b[0m   new_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcls_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/trax/optimizers/adam.py:56\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, learning_rate, weight_decay_rate, b1, b2, eps, clip_grad_norm)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, weight_decay_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,  \u001b[38;5;66;03m# pylint: disable=useless-super-delegation\u001b[39;00m\n\u001b[1;32m     39\u001b[0m              b1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, b2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m, clip_grad_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Creates an Adam optimizer.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        (This is not part of the core Adam algorithm.)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m      \u001b[49m\u001b[43mweight_decay_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m      \u001b[49m\u001b[43mb1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m      \u001b[49m\u001b[43mb2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m      \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclip_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclip_grad_norm\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/trax/optimizers/base.py:60\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, learning_rate, clip_grad_norm, **init_opt_params)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sets initial hyperparameter values for this optimizer.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mTakes optimizer hyperparameters as keyword arguments. These values can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m  **init_opt_params: Initial values of any additional optimizer parameters.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m init_opt_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m learning_rate\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_opt_params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     61\u001b[0m     name: jnp\u001b[38;5;241m.\u001b[39marray(value) \u001b[38;5;28;01mfor\u001b[39;00m (name, value) \u001b[38;5;129;01min\u001b[39;00m init_opt_params\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     62\u001b[0m }\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Gradient clipping happens with respect to the norm of the whole gradient\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# tree, so it is not passed to single-slot updates, but done in this class\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# for the whole gradient tree.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/trax/optimizers/base.py:61\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Sets initial hyperparameter values for this optimizer.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mTakes optimizer hyperparameters as keyword arguments. These values can\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m  **init_opt_params: Initial values of any additional optimizer parameters.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m init_opt_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m learning_rate\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_opt_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 61\u001b[0m     name: \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (name, value) \u001b[38;5;129;01min\u001b[39;00m init_opt_params\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     62\u001b[0m }\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Gradient clipping happens with respect to the norm of the whole gradient\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# tree, so it is not passed to single-slot updates, but done in this class\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# for the whole gradient tree.\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:2051\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   2048\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input type for array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2050\u001b[0m out_array: Array \u001b[38;5;241m=\u001b[39m lax_internal\u001b[38;5;241m.\u001b[39m_convert_element_type(out, dtype, weak_type\u001b[38;5;241m=\u001b[39mweak_type)\n\u001b[0;32m-> 2051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndmin \u001b[38;5;241m>\u001b[39m ndim(out_array):\n\u001b[1;32m   2052\u001b[0m   out_array \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mexpand_dims(out_array, \u001b[38;5;28mrange\u001b[39m(ndmin \u001b[38;5;241m-\u001b[39m ndim(out_array)))\n\u001b[1;32m   2053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_array\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/lax/lax.py:592\u001b[0m, in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Elementwise clamp.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m  Returns :math:`\\mathrm{clamp}(x) = \\begin{cases}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m  \\end{cases}`.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    590\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m clamp_p\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;28mmin\u001b[39m, x, \u001b[38;5;28mmax\u001b[39m)\n\u001b[0;32m--> 592\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate\u001b[39m(operands: Union[Array, Sequence[ArrayLike]], dimension: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    593\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Concatenates a sequence of arrays along `dimension`.\u001b[39;00m\n\u001b[1;32m    594\u001b[0m \n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m  Wraps XLA's `Concatenate\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;124;03m    An array containing the concatenation.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    607\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/core.py:360\u001b[0m, in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLiteral(val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    358\u001b[0m literalable_types: Set[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 360\u001b[0m Atom \u001b[38;5;241m=\u001b[39m Union[Var, Literal]\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPrimitive\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m   name: \u001b[38;5;28mstr\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPrimitive\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m   name: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m    364\u001b[0m   \u001b[38;5;66;03m# set for multi-output primitives.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m   multiple_results: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/core.py:807\u001b[0m, in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_custom_vjp_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, fun, fwd, bwd, tracers, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_):  \u001b[38;5;66;03m# pytype: disable=signature-mismatch\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m primitive, fwd, bwd, _  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m new_sublevel():\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fun\u001b[38;5;241m.\u001b[39mcall_wrapped(\u001b[38;5;241m*\u001b[39mtracers)\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/dispatch.py:122\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, OrigShardings):\n\u001b[1;32m    121\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(s, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_original_sharding\u001b[39m\u001b[38;5;124m\"\u001b[39m, s) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(o, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_original_sharding\u001b[39m\u001b[38;5;124m\"\u001b[39m, o)\n\u001b[1;32m    123\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m s, o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshardings, other\u001b[38;5;241m.\u001b[39mshardings))\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/util.py:254\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m       out\u001b[38;5;241m.\u001b[39mappend(n)\n\u001b[1;32m    252\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_merge\u001b[39m(predicate, xs):\n\u001b[1;32m    255\u001b[0m   sides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(predicate, xs))\n\u001b[1;32m    256\u001b[0m   lhs \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(xs, sides) \u001b[38;5;28;01mif\u001b[39;00m s]\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/util.py:247\u001b[0m, in \u001b[0;36mcached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_remove_duplicates\u001b[39m(node_list):\n\u001b[1;32m    246\u001b[0m   seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 247\u001b[0m   out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    248\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m node_list:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(n) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m seen:\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/dispatch.py:201\u001b[0m, in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mblock_until_ready\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    200\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m token, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 201\u001b[0m     token[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mblock_until_ready()\n\u001b[1;32m    202\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_tokens\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    203\u001b[0m     token[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mblock_until_ready()\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/dispatch.py:353\u001b[0m, in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    349\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m subjaxpr \u001b[38;5;129;01min\u001b[39;00m core\u001b[38;5;241m.\u001b[39msubjaxprs(jaxpr):\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m jaxpr_shardings(subjaxpr)\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjaxpr_has_bints\u001b[39m(jaxpr: core\u001b[38;5;241m.\u001b[39mJaxpr) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    354\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28many\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v\u001b[38;5;241m.\u001b[39maval\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mis\u001b[39;00m core\u001b[38;5;241m.\u001b[39mbint \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m jaxpr\u001b[38;5;241m.\u001b[39minvars\n\u001b[1;32m    355\u001b[0m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v\u001b[38;5;241m.\u001b[39maval, core\u001b[38;5;241m.\u001b[39mUnshapedArray)) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    356\u001b[0m           \u001b[38;5;28many\u001b[39m(_is_bint_axis_size(d)\n\u001b[1;32m    357\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain([jaxpr], core\u001b[38;5;241m.\u001b[39msubjaxprs(jaxpr))\n\u001b[1;32m    358\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m j\u001b[38;5;241m.\u001b[39meqns \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39moutvars\n\u001b[1;32m    359\u001b[0m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v\u001b[38;5;241m.\u001b[39maval, core\u001b[38;5;241m.\u001b[39mDShapedArray) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m v\u001b[38;5;241m.\u001b[39maval\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_bint_axis_size\u001b[39m(d: core\u001b[38;5;241m.\u001b[39mAxisSize) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/dispatch.py:343\u001b[0m, in \u001b[0;36msharded_lowering\u001b[0;34m(fun, device, backend, name, donated_invars, always_lower, keep_unused, lowering_platform, *arg_specs)\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[38;5;28;01myield from\u001b[39;00m ((o, source_info) \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_shardings\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m eqn\u001b[38;5;241m.\u001b[39mprimitive \u001b[38;5;129;01mis\u001b[39;00m shard_map\u001b[38;5;241m.\u001b[39mshard_map_p:\n\u001b[1;32m    342\u001b[0m   source_info \u001b[38;5;241m=\u001b[39m SourceInfo(source_info_util\u001b[38;5;241m.\u001b[39msummarize(eqn\u001b[38;5;241m.\u001b[39msource_info),\n\u001b[0;32m--> 343\u001b[0m                             eqn\u001b[38;5;241m.\u001b[39mprimitive\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    344\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_names_to_pspec\u001b[39m(names):\n\u001b[1;32m    345\u001b[0m     ndmin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(names) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/interpreters/pxla.py:2947\u001b[0m, in \u001b[0;36mlower_sharding_computation\u001b[0;34m(fun_or_jaxpr, api_name, fun_name, in_shardings, out_shardings, donated_invars, global_in_avals, in_is_global, keep_unused, always_lower, devices_from_context, lowering_platform)\u001b[0m\n\u001b[1;32m   2943\u001b[0m out_shardings \u001b[38;5;241m=\u001b[39m _out_shardings_for_trivial(\n\u001b[1;32m   2944\u001b[0m     jaxpr, consts, in_shardings, da_object\u001b[38;5;241m.\u001b[39mdevice_assignment)\n\u001b[1;32m   2946\u001b[0m input_indices \u001b[38;5;241m=\u001b[39m _get_input_indices(global_in_avals, in_shardings, da_object)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 2947\u001b[0m handle_outs \u001b[38;5;241m=\u001b[39m global_avals_to_results_handler(\n\u001b[1;32m   2948\u001b[0m     global_out_avals, out_shardings, committed,\n\u001b[1;32m   2949\u001b[0m     [\u001b[38;5;28;01mFalse\u001b[39;00m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(global_out_avals))\n\u001b[1;32m   2950\u001b[0m \u001b[38;5;66;03m# Use the standard out_handler.\u001b[39;00m\n\u001b[1;32m   2951\u001b[0m unsafe_call \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mcompile_replicated(\n\u001b[1;32m   2952\u001b[0m     is_trivial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, jaxpr\u001b[38;5;241m=\u001b[39mjaxpr, consts\u001b[38;5;241m=\u001b[39mconsts,\n\u001b[1;32m   2953\u001b[0m     device_assignment\u001b[38;5;241m=\u001b[39mda_object\u001b[38;5;241m.\u001b[39mdevice_assignment, in_avals\u001b[38;5;241m=\u001b[39mglobal_in_avals,\n\u001b[1;32m   2954\u001b[0m     in_indices\u001b[38;5;241m=\u001b[39minput_indices, in_shardings\u001b[38;5;241m=\u001b[39min_shardings,\n\u001b[1;32m   2955\u001b[0m     kept_var_idx\u001b[38;5;241m=\u001b[39mkept_var_idx, out_handler\u001b[38;5;241m=\u001b[39mhandle_outs,\n\u001b[1;32m   2956\u001b[0m     out_shardings\u001b[38;5;241m=\u001b[39mout_shardings, pmap_nreps\u001b[38;5;241m=\u001b[39mpmap_nreps)\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/_src/dispatch.py:570\u001b[0m, in \u001b[0;36mjaxpr_shardings\u001b[0;34m(jaxpr)\u001b[0m\n\u001b[1;32m    564\u001b[0m       raise\n\u001b[1;32m    565\u001b[0m     warnings.warn(\n\u001b[1;32m    566\u001b[0m         f\"Error writing persistent compilation cache entry for \"\n\u001b[1;32m    567\u001b[0m         f\"'{module_name}': {type(ex).__name__}: {ex}\")\n\u001b[0;32m--> 570\u001b[0m # TODO(yashkatariya): Generalize is_compatible_aval (maybe renamed) and use that\n\u001b[1;32m    571\u001b[0m # to check if shardings are compatible with the input.\n\u001b[1;32m    572\u001b[0m def _check_sharding(aval, s):\n\u001b[1;32m    573\u001b[0m   from jax._src import pjit\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/jax/experimental/shard_map.py:50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _shared_code_pmap, _prepare_pmap\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlax\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (lax, parallel \u001b[38;5;28;01mas\u001b[39;00m lax_parallel, slicing,\n\u001b[1;32m     49\u001b[0m                           windowed_reductions, fft, linalg, control_flow)\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (HashableFunction, HashablePartial, unzip2, unzip3,\n\u001b[1;32m     51\u001b[0m                            as_hashable_function, memoize, partition_list,\n\u001b[1;32m     52\u001b[0m                            merge_lists, split_list)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flatten_fun_nokwargs, shaped_abstractify\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_src\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpreters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m batching\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'HashablePartial' from 'jax._src.util' (/usr/local/lib/python3.8/site-packages/jax/_src/util.py)\n  In call to configurable 'Adam' (<class 'trax.optimizers.adam.Adam'>)"],"ename":"ImportError","evalue":"cannot import name 'HashablePartial' from 'jax._src.util' (/usr/local/lib/python3.8/site-packages/jax/_src/util.py)\n  In call to configurable 'Adam' (<class 'trax.optimizers.adam.Adam'>)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\neval_task = training.EvalTask(\n    \n    ## use the eval batch stream as labeled data\n    labeled_data=val_batch_stream,\n    \n    ## use the cross entropy loss and accuracy as metrics\n    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-30T17:21:35.531652Z","iopub.execute_input":"2023-05-30T17:21:35.532081Z","iopub.status.idle":"2023-05-30T17:23:08.069469Z","shell.execute_reply.started":"2023-05-30T17:21:35.532046Z","shell.execute_reply":"2023-05-30T17:23:08.068444Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# define the output directory\noutput_dir = 'output_dir/'\n\n\n# define the training loop\ntraining_loop = training.Loop(NMTAttn(mode='train'),\n                              train_task,\n                              eval_tasks=[eval_task],\n                              output_dir=output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-05-30T17:26:49.260457Z","iopub.execute_input":"2023-05-30T17:26:49.260904Z","iopub.status.idle":"2023-05-30T17:26:59.405106Z","shell.execute_reply.started":"2023-05-30T17:26:49.260869Z","shell.execute_reply":"2023-05-30T17:26:59.403456Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"2023-05-30 17:26:59.310080: E external/xla/xla/pjrt/pjrt_stream_executor_client.cc:2432] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886464 bytes.\nBufferAssignment OOM Debugging.\nBufferAssignment stats:\n             parameter allocation:        16B\n              constant allocation:         0B\n        maybe_live_out allocation:   32.00MiB\n     preallocated temp allocation:   80.00MiB\n  preallocated temp fragmentation:         0B (0.00%)\n                 total allocation:  112.00MiB\n              total fragmentation:   16.00MiB (14.29%)\nPeak buffers:\n\tBuffer 1:\n\t\tSize: 32.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/max\" source_file=\"/tmp/ipykernel_29/2642057364.py\" source_line=6\n\t\tXLA Label: fusion\n\t\tShape: f32[2048,4096]\n\t\t==========================\n\n\tBuffer 2:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=\"/tmp/ipykernel_29/2642057364.py\" source_line=6\n\t\tXLA Label: custom-call\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\tBuffer 3:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=\"/tmp/ipykernel_29/2642057364.py\" source_line=6\n\t\tXLA Label: custom-call\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\tBuffer 4:\n\t\tSize: 16.00MiB\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\tBuffer 5:\n\t\tSize: 16.00MiB\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\tBuffer 6:\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=\"/tmp/ipykernel_29/2642057364.py\" source_line=6\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\tBuffer 7:\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=\"/tmp/ipykernel_29/2642057364.py\" source_line=6\n\t\tXLA Label: fusion\n\t\tShape: (u32[4194304], u32[4194304])\n\t\t==========================\n\n\tBuffer 8:\n\t\tSize: 16B\n\t\tXLA Label: fusion\n\t\tShape: (u32[4194304], u32[4194304])\n\t\t==========================\n\n\tBuffer 9:\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=\"/tmp/ipykernel_29/2642057364.py\" source_line=6\n\t\tXLA Label: custom-call\n\t\tShape: (u32[4194304], u32[4194304])\n\t\t==========================\n\n\tBuffer 10:\n\t\tSize: 8B\n\t\tEntry Parameter Subshape: u32[2]\n\t\t==========================\n\n\tBuffer 11:\n\t\tSize: 4B\n\t\tEntry Parameter Subshape: f32[]\n\t\t==========================\n\n\tBuffer 12:\n\t\tSize: 4B\n\t\tEntry Parameter Subshape: f32[]\n\t\t==========================\n\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLayerError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# define the training loop\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m training_loop \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNMTAttn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mtrain_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                              \u001b[49m\u001b[43meval_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43meval_task\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trax/supervised/training.py:248\u001b[0m, in \u001b[0;36mLoop.__init__\u001b[0;34m(self, model, tasks, eval_model, eval_tasks, output_dir, checkpoint_at, checkpoint_low_metric, checkpoint_high_metric, permanent_checkpoint_at, eval_at, which_task, n_devices, random_seed, loss_chunk_size, use_memory_efficient_trainer, adasum, callbacks)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_memory_efficient_trainer:\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _is_uninitialized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_model\u001b[38;5;241m.\u001b[39mrng \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_rng()\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _is_uninitialized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_model):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trax/layers/base.py:310\u001b[0m, in \u001b[0;36mLayer.init\u001b[0;34m(self, input_signature, rng, use_cache)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m   \u001b[38;5;66;03m# Skipping 3 lines as it's always the uninteresting internal call.\u001b[39;00m\n\u001b[1;32m    309\u001b[0m   name, trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, _short_traceback(skip\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 310\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m LayerError(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_caller,\n\u001b[1;32m    311\u001b[0m                    input_signature, trace) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mLayerError\u001b[0m: Exception passing through layer Serial (in init):\n  layer created in file [...]/tmp/ipykernel_29/3503318463.py, line 39\n  layer input shapes: (ShapeDtype{shape:(16, 64, 1024), dtype:float64}, ShapeDtype{shape:(16, 64), dtype:int64}, ShapeDtype{shape:(16, 64), dtype:float32})\n\n  File [...]/trax/layers/combinators.py, line 107, in init_weights_and_state\n    sublayer.init(inputs, use_cache=True))\n\nLayerError: Exception passing through layer Parallel (in init):\n  layer created in file [...]/tmp/ipykernel_29/3503318463.py, line 45\n  layer input shapes: (ShapeDtype{shape:(16, 64, 1024), dtype:float32}, ShapeDtype{shape:(16, 64), dtype:int32})\n\n  File [...]/trax/layers/combinators.py, line 226, in init_weights_and_state\n    inits = [layer.init(signature, use_cache=True)\n\n  File [...]/trax/layers/combinators.py, line 226, in <listcomp>\n    inits = [layer.init(signature, use_cache=True)\n\nLayerError: Exception passing through layer Serial (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 16\n  layer input shapes: ShapeDtype{shape:(16, 64, 1024), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 107, in init_weights_and_state\n    sublayer.init(inputs, use_cache=True))\n\nLayerError: Exception passing through layer LSTM_1024 (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 19\n  layer input shapes: ShapeDtype{shape:(16, 64, 1024), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 107, in init_weights_and_state\n    sublayer.init(inputs, use_cache=True))\n\nLayerError: Exception passing through layer Scan (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 19\n  layer input shapes: (ShapeDtype{shape:(16, 64, 1024), dtype:float32}, ShapeDtype{shape:(16, 2048), dtype:float32})\n\n  File [...]/trax/layers/combinators.py, line 470, in init_weights_and_state\n    weights, state = self.sublayer.init(layer_signature, use_cache=True)\n\nLayerError: Exception passing through layer LSTMCell (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 19\n  layer input shapes: (ShapeDtype{shape:(16, 1024), dtype:float32}, ShapeDtype{shape:(16, 2048), dtype:float32})\n\n  File [...]/trax/layers/rnn.py, line 76, in init_weights_and_state\n    w = self._kernel_initializer((input_shape, 4 * self._n_units), rng1)\n\n  File [...]/trax/layers/initializers.py, line 118, in Init\n    return random.uniform(rng, shape, jnp.float32, -lim, lim)\n\n  File [...]/trax/fastmath/ops.py, line 77, in uniform\n    return backend()['random_uniform'](*args, **kwargs)\n\n  File [...]/jax/_src/random.py, line 298, in uniform\n    return _uniform(key, shape, dtype, minval, maxval)  # type: ignore\n\n  File [...]/jax/_src/traceback_util.py, line 166, in reraise_with_filtered_traceback\n    return fun(*args, **kwargs)\n\n  File [...]/jax/_src/pjit.py, line 208, in cache_miss\n    outs, out_flat, out_tree, args_flat = _python_pjit_helper(\n\n  File [...]/jax/_src/pjit.py, line 155, in _python_pjit_helper\n    out_flat = pjit_p.bind(*args_flat, **params)\n\n  File [...]/jax/_src/core.py, line 2633, in bind\n    return self.bind_with_trace(top_trace, args, params)\n\n  File [...]/jax/_src/core.py, line 383, in bind_with_trace\n    out = trace.process_primitive(self, map(trace.full_raise, args), params)\n\n  File [...]/jax/_src/core.py, line 790, in process_primitive\n    return primitive.impl(*tracers, **params)\n\n  File [...]/jax/_src/pjit.py, line 1108, in _pjit_call_impl\n    return compiled.unsafe_call(*args)\n\n  File [...]/jax/_src/profiler.py, line 314, in wrapper\n    return func(*args, **kwargs)\n\n  File [...]/_src/interpreters/pxla.py, line 1346, in __call__\n    results = self.xla_executable.execute_sharded(input_bufs)\n\njaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886464 bytes.\nBufferAssignment OOM Debugging.\n\nBufferAssignment stats:\n             parameter allocation:        16B\n\n              constant allocation:         0B\n        maybe_live_out allocation:   32.00MiB\n\n     preallocated temp allocation:   80.00MiB\n  preallocated temp fragmentation:         0B (0.00%)\n\n                 total allocation:  112.00MiB\n              total fragmentation:   16.00MiB (14.29%)\n\nPeak buffers:\n\tBuffer 1:\n\n\t\tSize: 32.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/max\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\n\t\tXLA Label: fusion\n\t\tShape: f32[2048,4096]\n\n\t\t==========================\n\n\n\tBuffer 2:\n\t\tSize: 16.00MiB\n\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\t\tXLA Label: custom-call\n\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\n\tBuffer 3:\n\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\n\t\tXLA Label: custom-call\n\t\tShape: u32[4194304]\n\n\t\t==========================\n\n\n\tBuffer 4:\n\t\tSize: 16.00MiB\n\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\n\t\t==========================\n\n\n\tBuffer 5:\n\t\tSize: 16.00MiB\n\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\n\t\t==========================\n\n\n\tBuffer 6:\n\t\tSize: 16.00MiB\n\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\t\tXLA Label: fusion\n\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\n\tBuffer 7:\n\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\n\t\tXLA Label: fusion\n\t\tShape: (u32[4194304], u32[4194304])\n\n\t\t==========================\n\n\n\tBuffer 8:\n\t\tSize: 16B\n\n\t\tXLA Label: fusion\n\t\tShape: (u32[4194304], u32[4194304])\n\n\t\t==========================\n\n\n\tBuffer 9:\n\t\tSize: 16B\n\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\t\tXLA Label: custom-call\n\n\t\tShape: (u32[4194304], u32[4194304])\n\t\t==========================\n\n\n\tBuffer 10:\n\n\t\tSize: 8B\n\t\tEntry Parameter Subshape: u32[2]\n\n\t\t==========================\n\n\n\tBuffer 11:\n\t\tSize: 4B\n\n\t\tEntry Parameter Subshape: f32[]\n\t\t==========================\n\n\n\tBuffer 12:\n\n\t\tSize: 4B\n\t\tEntry Parameter Subshape: f32[]\n\n\t\t==========================\n\n\n"],"ename":"LayerError","evalue":"Exception passing through layer Serial (in init):\n  layer created in file [...]/tmp/ipykernel_29/3503318463.py, line 39\n  layer input shapes: (ShapeDtype{shape:(16, 64, 1024), dtype:float64}, ShapeDtype{shape:(16, 64), dtype:int64}, ShapeDtype{shape:(16, 64), dtype:float32})\n\n  File [...]/trax/layers/combinators.py, line 107, in init_weights_and_state\n    sublayer.init(inputs, use_cache=True))\n\nLayerError: Exception passing through layer Parallel (in init):\n  layer created in file [...]/tmp/ipykernel_29/3503318463.py, line 45\n  layer input shapes: (ShapeDtype{shape:(16, 64, 1024), dtype:float32}, ShapeDtype{shape:(16, 64), dtype:int32})\n\n  File [...]/trax/layers/combinators.py, line 226, in init_weights_and_state\n    inits = [layer.init(signature, use_cache=True)\n\n  File [...]/trax/layers/combinators.py, line 226, in <listcomp>\n    inits = [layer.init(signature, use_cache=True)\n\nLayerError: Exception passing through layer Serial (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 16\n  layer input shapes: ShapeDtype{shape:(16, 64, 1024), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 107, in init_weights_and_state\n    sublayer.init(inputs, use_cache=True))\n\nLayerError: Exception passing through layer LSTM_1024 (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 19\n  layer input shapes: ShapeDtype{shape:(16, 64, 1024), dtype:float32}\n\n  File [...]/trax/layers/combinators.py, line 107, in init_weights_and_state\n    sublayer.init(inputs, use_cache=True))\n\nLayerError: Exception passing through layer Scan (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 19\n  layer input shapes: (ShapeDtype{shape:(16, 64, 1024), dtype:float32}, ShapeDtype{shape:(16, 2048), dtype:float32})\n\n  File [...]/trax/layers/combinators.py, line 470, in init_weights_and_state\n    weights, state = self.sublayer.init(layer_signature, use_cache=True)\n\nLayerError: Exception passing through layer LSTMCell (in init):\n  layer created in file [...]/tmp/ipykernel_29/4034324487.py, line 19\n  layer input shapes: (ShapeDtype{shape:(16, 1024), dtype:float32}, ShapeDtype{shape:(16, 2048), dtype:float32})\n\n  File [...]/trax/layers/rnn.py, line 76, in init_weights_and_state\n    w = self._kernel_initializer((input_shape, 4 * self._n_units), rng1)\n\n  File [...]/trax/layers/initializers.py, line 118, in Init\n    return random.uniform(rng, shape, jnp.float32, -lim, lim)\n\n  File [...]/trax/fastmath/ops.py, line 77, in uniform\n    return backend()['random_uniform'](*args, **kwargs)\n\n  File [...]/jax/_src/random.py, line 298, in uniform\n    return _uniform(key, shape, dtype, minval, maxval)  # type: ignore\n\n  File [...]/jax/_src/traceback_util.py, line 166, in reraise_with_filtered_traceback\n    return fun(*args, **kwargs)\n\n  File [...]/jax/_src/pjit.py, line 208, in cache_miss\n    outs, out_flat, out_tree, args_flat = _python_pjit_helper(\n\n  File [...]/jax/_src/pjit.py, line 155, in _python_pjit_helper\n    out_flat = pjit_p.bind(*args_flat, **params)\n\n  File [...]/jax/_src/core.py, line 2633, in bind\n    return self.bind_with_trace(top_trace, args, params)\n\n  File [...]/jax/_src/core.py, line 383, in bind_with_trace\n    out = trace.process_primitive(self, map(trace.full_raise, args), params)\n\n  File [...]/jax/_src/core.py, line 790, in process_primitive\n    return primitive.impl(*tracers, **params)\n\n  File [...]/jax/_src/pjit.py, line 1108, in _pjit_call_impl\n    return compiled.unsafe_call(*args)\n\n  File [...]/jax/_src/profiler.py, line 314, in wrapper\n    return func(*args, **kwargs)\n\n  File [...]/_src/interpreters/pxla.py, line 1346, in __call__\n    results = self.xla_executable.execute_sharded(input_bufs)\n\njaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 83886464 bytes.\nBufferAssignment OOM Debugging.\n\nBufferAssignment stats:\n             parameter allocation:        16B\n\n              constant allocation:         0B\n        maybe_live_out allocation:   32.00MiB\n\n     preallocated temp allocation:   80.00MiB\n  preallocated temp fragmentation:         0B (0.00%)\n\n                 total allocation:  112.00MiB\n              total fragmentation:   16.00MiB (14.29%)\n\nPeak buffers:\n\tBuffer 1:\n\n\t\tSize: 32.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/max\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\n\t\tXLA Label: fusion\n\t\tShape: f32[2048,4096]\n\n\t\t==========================\n\n\n\tBuffer 2:\n\t\tSize: 16.00MiB\n\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\t\tXLA Label: custom-call\n\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\n\tBuffer 3:\n\n\t\tSize: 16.00MiB\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\n\t\tXLA Label: custom-call\n\t\tShape: u32[4194304]\n\n\t\t==========================\n\n\n\tBuffer 4:\n\t\tSize: 16.00MiB\n\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\n\t\t==========================\n\n\n\tBuffer 5:\n\t\tSize: 16.00MiB\n\n\t\tXLA Label: fusion\n\t\tShape: u32[4194304]\n\n\t\t==========================\n\n\n\tBuffer 6:\n\t\tSize: 16.00MiB\n\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\t\tXLA Label: fusion\n\n\t\tShape: u32[4194304]\n\t\t==========================\n\n\n\tBuffer 7:\n\n\t\tSize: 16B\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\n\t\tXLA Label: fusion\n\t\tShape: (u32[4194304], u32[4194304])\n\n\t\t==========================\n\n\n\tBuffer 8:\n\t\tSize: 16B\n\n\t\tXLA Label: fusion\n\t\tShape: (u32[4194304], u32[4194304])\n\n\t\t==========================\n\n\n\tBuffer 9:\n\t\tSize: 16B\n\n\t\tOperator: op_name=\"jit(_uniform)/jit(main)/threefry2x32\" source_file=[...]/tmp/ipykernel_29/2642057364.py source_line=6\n\t\tXLA Label: custom-call\n\n\t\tShape: (u32[4194304], u32[4194304])\n\t\t==========================\n\n\n\tBuffer 10:\n\n\t\tSize: 8B\n\t\tEntry Parameter Subshape: u32[2]\n\n\t\t==========================\n\n\n\tBuffer 11:\n\t\tSize: 4B\n\n\t\tEntry Parameter Subshape: f32[]\n\t\t==========================\n\n\n\tBuffer 12:\n\n\t\tSize: 4B\n\t\tEntry Parameter Subshape: f32[]\n\n\t\t==========================\n\n\n","output_type":"error"}]},{"cell_type":"code","source":"n_step=int(len(train_list)/32)*100\nprint(n_step)\ntraining_loop.run(n_step)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-08T14:25:42.613152Z","iopub.execute_input":"2023-05-08T14:25:42.614317Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"146\n37\n25\n30\n34\n31\n33\n47\n39\n33\n35\n58\n58\n54\n52\n17\n33\n31\n50\n31\n26\n37\n56\n40\n35\n33\n57\n42\n30\n44\n43\n28\n61\n29\n39\n33\n31\n36\n29\n54\n20\n36\n16\n30\n22\n43\n34\n43\n32\n34\nencoder_activations is (4, 64, 1024)\nshape of mask is (4, 1, 64, 64)\n\nStep      1: Total number of trainable weights: 247668776\nStep      1: Ran 1 train steps in 442.16 secs\nStep      1: train CrossEntropyLoss |  4.13491631\n29\n45\n43\n32\n32\n47\n35\n17\n31\n36\n47\n18\n30\n27\n41\n38\n24\n31\n45\n41\n57\n30\n25\n57\n41\n23\n34\n36\n24\n38\n28\n34\n29\n33\n40\n49\n40\n39\n31\n36\n39\n25\n30\n29\n40\n39\n22\n46\n34\n54\n44\n41\n37\nencoder_activations is (4, 64, 1024)\nshape of mask is (4, 1, 64, 64)\nStep      1: eval  CrossEntropyLoss |  3.69793653\nStep      1: eval          Accuracy |  0.02941176\n34\n23\n46\n39\n36\n40\n14\n30\n41\n28\n13\n32\n18\n31\n29\n12\n16\n21\n27\n27\n45\n33\n30\n32\n42\n31\n61\n17\n23\n45\n25\n57\n52\n31\n28\n20\n38\n42\n58\n38\n31\n45\n33\n40\n31\n31\n58\n30\n29\n33\n32\n20\n42\n50\n29\n19\n37\n50\n28\nencoder_activations is (8, 32, 1024)\nshape of mask is (8, 1, 32, 32)\n\nStep      2: Ran 1 train steps in 464.60 secs\nStep      2: train CrossEntropyLoss |  3.73095965\n33\n22\n32\n55\n46\n29\n32\n58\n22\n42\n37\n30\n32\n38\n44\n34\n50\n45\n36\n48\n18\n31\n33\n25\n48\n52\n45\n55\n39\n42\n23\n27\n29\n53\n33\n29\n35\n30\n31\n61\n31\n19\n42\n34\n35\n37\n19\n38\n28\n30\n36\n31\n29\n45\n15\n25\nencoder_activations is (8, 32, 1024)\nshape of mask is (8, 1, 32, 32)\nStep      2: eval  CrossEntropyLoss |  3.52988172\nStep      2: eval          Accuracy |  0.08762887\n22\n14\n34\n59\n40\n40\n24\n24\n28\n34\n32\n31\n34\n\nStep      3: Ran 1 train steps in 211.83 secs\nStep      3: train CrossEntropyLoss |  3.48609209\n29\n39\nStep      3: eval  CrossEntropyLoss |  3.44697523\nStep      3: eval          Accuracy |  0.09795322\n34\n41\n39\n36\n35\n38\n29\n33\n34\n38\n24\n43\n60\n32\n25\n29\n32\n28\n23\n31\n20\n32\n51\n26\n27\n20\n38\n45\n56\n32\n31\n56\n55\n36\n37\n35\n16\n35\n28\n34\n26\n47\n45\n37\n41\n35\n52\n24\n26\n60\n32\n58\n44\n28\n33\n\nStep      4: Ran 1 train steps in 418.64 secs\nStep      4: train CrossEntropyLoss |  3.36915708\n33\n34\n44\n14\n60\n31\n48\n37\n25\n32\n28\n48\n37\n15\n45\n55\n42\n38\n31\n39\n19\n27\n33\n44\n33\n47\n40\n28\n30\n31\n30\n31\n43\n31\n31\n39\n54\n38\n55\n34\n25\n23\n38\n45\n44\n30\n37\n28\n15\n36\n55\n21\n30\n24\n28\n28\n31\n20\n28\n31\n60\n54\nStep      4: eval  CrossEntropyLoss |  3.42442918\nStep      4: eval          Accuracy |  0.09215263\n24\n34\n37\n34\n37\n59\n36\n44\n37\n48\n40\n21\n14\n38\n35\n36\n16\n26\n24\n30\n33\n33\n42\n38\n30\n35\n36\n31\n24\n32\n35\n43\n35\n31\n44\n34\n62\n34\n23\n22\n39\n59\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                \n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working/output_dir'\nremove_folder_contents(folder_path)\nos.rmdir(r'/kaggle/working/output_dir')","metadata":{"execution":{"iopub.status.busy":"2023-04-27T01:18:42.056057Z","iopub.execute_input":"2023-04-27T01:18:42.056517Z","iopub.status.idle":"2023-04-27T01:18:42.170403Z","shell.execute_reply.started":"2023-04-27T01:18:42.056466Z","shell.execute_reply":"2023-04-27T01:18:42.169084Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"#(batch,timestep)\n#embedding\n#(batch,timestep,n_dimension)\n#(batch,timestep,w,h,channel)\n#(batch,timestep,1024)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T18:32:43.234574Z","iopub.execute_input":"2023-06-05T18:32:43.235540Z","iopub.status.idle":"2023-06-05T18:32:43.239224Z","shell.execute_reply.started":"2023-06-05T18:32:43.235507Z","shell.execute_reply":"2023-06-05T18:32:43.238209Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T18:22:02.041830Z","iopub.execute_input":"2023-04-26T18:22:02.042337Z","iopub.status.idle":"2023-04-26T18:22:02.048695Z","shell.execute_reply.started":"2023-04-26T18:22:02.042284Z","shell.execute_reply":"2023-04-26T18:22:02.047223Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-04-26T18:25:29.190228Z","iopub.execute_input":"2023-04-26T18:25:29.190671Z","iopub.status.idle":"2023-04-26T18:25:29.196639Z","shell.execute_reply.started":"2023-04-26T18:25:29.190637Z","shell.execute_reply":"2023-04-26T18:25:29.195426Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-08T13:06:35.842660Z","iopub.execute_input":"2023-05-08T13:06:35.843663Z","iopub.status.idle":"2023-05-08T13:06:36.586750Z","shell.execute_reply.started":"2023-05-08T13:06:35.843609Z","shell.execute_reply":"2023-05-08T13:06:36.585527Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-05-08T13:06:36.589043Z","iopub.execute_input":"2023-05-08T13:06:36.589687Z","iopub.status.idle":"2023-05-08T13:06:37.067402Z","shell.execute_reply.started":"2023-05-08T13:06:36.589617Z","shell.execute_reply":"2023-05-08T13:06:37.066366Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}